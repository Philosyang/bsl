[["index.html", "Basics of Statistical Learning Welcome 0.1 Who? 0.2 What? 0.3 Why? 0.4 Where? 0.5 When? 0.6 How?", " Basics of Statistical Learning David Dalpiaz Welcome Welcome to Basics of Statistical Learning! What a boring title! The title was chosen to mirror that of the University of Illinois at Urbana-Champaign course STAT 432 - Basics of Statistical Learning. That title was chosen to meet certain University course naming conventions, hence the boring title. A more appropriate title would be a broad introduction to machine learning from the perspective of a statistician who uses R1 and emphasizes practice over theory. This is more descriptive, still boring, and way too many words. Anyway, this “book” will be referred to as BSL for short. This chapter will outline the who, what, when, where, why, and how2 of this book, but not necessarily in that order. 0.1 Who? 0.1.1 Readers This book is targeted at advanced undergraduate or first year MS students in Statistics who have no prior machine learning experience. While both will be discussed in great detail, previous experience with both statistical modeling and R are assumed. In other words, this books is for students in STAT 4323. If you are reading this book but are not involved in STAT 432, we assume: a semester of calculus based probability and statistics familiarity with linear algebra enough understanding of linear models and R to be able to use R’s formula syntax to specify models 0.1.2 Author This text was written by David Dalpiaz4. 0.1.3 Acknowledgements The following is a (likely incomplete) list of helpful contributors. This book was also influenced by the helpful contributors to R4SL. Jae-Ho Lee - STAT 432, Fall 2019 W. Jonas Reger - STAT 432, Spring 2020 Please see the CONTRIBUTING document on GitHub for details on interacting with this project. Pull requests encouraged! 0.2 What? Well, this is a book. But you already knew that. More specifically, this is a book for use in STAT 432. But if you are reading this chapter, you’re either not in STAT 432, or new to STAT 432, so that isn’t really helpful. This is a book about machine learning. But this is too vague a description. It is probably most useful to describe the desired outcome as a result of reading this book. In a single sentence: After engaging with BSL, readers should feel comfortable training predictive models and evaluating their use as part of larger systems or data anlyses. This sentence is both too specific and too general, so some additional comments about what will and will not be discussed in this text: An ability to train models will be emphasized over the ability to understand models at a deep theoretical level. This is not to say that theory will be completely ignored, but some theory will be sacrificed for practicality. Theory5 will be explored especially when it motivates use in practice. Evaluation of models is emphasized as the author takes the position6 that in practice it is more important to know if your model works than how your model works. Rather than making an attempt to illustrate all possible modeling techniques7, a small set of techniques are emphasized: linear models, nearest neighbors, and decision trees. These will initially serve as examples for theory discussions, but will then become the building blocks for more complex techniques such as lasso, ridge, and random forests. While the set of models discussed will be limited8, the emphasis on an ability to train and evaluate these models should allow a reader to train and evaluate any model in a predictive context, provided it is implemented in a statistical computing environment9. For a better understanding of the specific topics covered, please see the next chapter which serves as an overview of the text. To be clear: This book is not an exhaustive treatment of machine learning. If this is your first brush with machine learning, hopefully it is not your last! 0.3 Why? Why does this book exists? That is a very good question, especially given the existence of An Introduction to Statistical Learning10, the immensely popular book11 by James, Witten, Hastie, and Tibshirani. The author of this text believes ISL is a great text12, so much so that he would suggest that any readers of BSL also read all of ISL13. Despite this, a book that was more inline with the content and goals of STAT 43214 was conceived by the author, so here we are. Why does STAT 432 exist? Short answer: to add a course on machine learning to the undergraduate Statistics curriculum at the University of Illinois. The long story is long, but two individuals deserve credit for their work in the background: Ehsan Bokhari for introducing the author to ISL and suggesting that it would make a good foundation for an undergraduate course. Jeff Douglas for actually getting the pilot version of STAT 432 off the ground15. 0.4 Where? Currently, this text is used exclusively16 for STAT 43217 at the University of Illinois at Urbana-Champaign. The text can be accessed from https://statisticallearning.org/. 0.5 When? This book was last updated on: 2020-08-27.18 0.6 How? Knowing a bit about how this book was built will help readers better interact with the text. 0.6.1 Build Tools This book is authored using Bookdown19, built using Travis-CI, and hosted via GitHub pages. Details of this setup can be found by browser the relevant GitHub repository.20 Users that are familiar with these tools, most importantly GitHub, are encouraged to contribute. As noted above, please see the CONTRIBUTING document on GitHub for details on interacting with this project. 0.6.2 Active Development This “book” is under active development. Literally every element of the book is subject to change, at any moment. This text, BSL, is the successor to R4SL, an unfinished work that began as a supplement to Introduction to Statistical Learning, but was never finished. (In some sense, this book is just a fresh start due to the author wanting to change the presentation of the material. The author is seriously worried that he will encounter the second-system effect.21 Since this book is under active development you may encounter errors ranging from typos, to broken code, to poorly explained topics. If you do, please let us know! Better yet, fix the issue yourself!22 If you are familiar with R Markdown and GitHub, pull requests are highly encouraged!. This process is partially automated by the edit button in the top-left corner of the html version. If your suggestion or fix becomes part of the book, you will be added to the acknowledgments in this chapter this chapter. We’ll also link to your GitHub account, or personal website upon request. If you’re not familiar with version control systems feel free to email the author, dalpiaz2 AT illinois DOT edu.23 See additional details in the Acknowledgments section above. While development is taking place, you may see “TODO” items scattered throughout the text. These are mostly notes for internal use, but give the reader some idea of what development is still to come. 0.6.3 License This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License R Core Team, R: A Language and Environment for Statistical Computing (Vienna, Austria: R Foundation for Statistical Computing, 2016), https://www.R-project.org/↩ Wikipedia: Five Ws↩ STAT 432 is also cross-listed as ASRM 451, but we will exclusively refer to STAT 432 for simplicity.↩ He does not enjoy writing about himself↩ Theory here is ill defined. Loosely, “theory” is activities that are closer to writing theorem-proof mathematics while “practice” is more akin to using built-in statistical computing tools in a language like R.↩ This is not a unique opinion.↩ This is impossible.↩ Students often ask if we will cover support vector machines or deep learning or insert latest buzzword model here. The author believes this is because students consider these to be “cool” methods. One of the goals of this text is to make machine learning seems as uncool as possible. The hope would be for readers to understand something like an SVM to be “just another method” which also needs to be evaluated. The author believes deep learning is useful, but would clutter the presentation because of the additional background and computing that would need to be introduced. Follow-up learning of deep learning is encouraged after reading BSL. Hopefully, by reading BSL, getting up to speed using deep learning will be made easier.↩ Also provided the user reads the documentation.↩ Gareth James et al., An Introduction to Statistical Learning, vol. 112 (Springer, 2013), http://faculty.marshall.usc.edu/gareth-james/ISL/↩ This book is generally referred to as ISL.↩ He has spent so much time referencing ISL that he found and suggested a typo fix.↩ One of the biggest strengths of ISL is its readability.↩ The biggest differences are: Assumed reader background, overall structure, and R code usage and style.↩ Jeff taught the first proto-version of STAT 432 as a topics course, but then allowed the author to take over teaching and development while he worked to get the course fully approved.↩ If you are using this text elsewhere, that’s great! Please let the author know!↩ https://stat432.org/↩ The author has no idea what else to write in this section, but the last updated date seems like useful information.↩ Yihui Xie, Bookdown: Authoring Books and Technical Documents with R Markdown, 2020, https://github.com/rstudio/bookdown↩ https://github.com/daviddalpiaz/bsl↩ Wikipedia: Second-System Effect↩ Yihui Xie: You Do Not Need to Tell Me I Have A Typo in My Documentation↩ But also consider using this opportunity to learn a bit about version control!↩ "],["ml-overview.html", "Chapter 1 Machine Learning Overview 1.1 What is Machine Learning? 1.2 Machine Learning Tasks 1.3 Open Questions", " Chapter 1 Machine Learning Overview This is a book about machine learning, so let’s try to define machine learning in this chapter. Specifically, we’ll discuss: What is machine learning? The difference between supervised learning and unsupervised learning. The difference between classification and regression. Source: ml-overview.Rmd 1.1 What is Machine Learning? Machine learning (ML) is about learning functions from data.24 That’s it. Really. Pretty boring, right?25 To quickly address some buzzwords that come up when discussing machine learning: Deep learning is a subset of machine learning. Artificial Intelligence (AI) overlaps machine learning but has much loftier goals. In general, if someone claims to be using AI, they are not. They’re probably using function learning! For example, we will learn logistic regression in this course. People in marketing might call that AI! Someone who understands ML will simply call it function learning. Don’t buy the hype! We don’t need to call simple methods AI to make them effective.26 Machine learning is not data science. Data science sometimes uses machine learning. Does big data exist? If it does, I would bet a lot of money that you haven’t seen it, and probably won’t see it that often. Analytics is just a fancy word for doing data analysis. Machine learning can be used in analyses! When it is, it is often called “Predictive Analytics.” What makes machine learning interesting are the uses of these learned functions. We could develop functions that have applications in a wide variety of fields. In medicine, we could develop a function that helps detect skin cancer. Input: Pixels from an image of mole Output: A probability that the mole is cancerous In sport analytics, we could develop a function that helps determine player salary. Input: Lifetime statistics of an NBA player Output: An estimate of player’s salary In meteorology, we could develop a function to predict the weather. Input: Historic weather data in Champaign, IL Output: A probability of rain tomorrow in Champaign, IL In political science we could develop a function that predicts the mood of the president. Input: The text of a tweet from President Donald Trump Output: A prediction of Donald’s mood (happy, sad, angry, etc) In urban planning we could develop a function that predicts the rental prices of Airbnbs. Input: The attributes of the location for rent Output: An estimate of the rent of the property How do we learn these functions? By looking at many previous examples, that is, data! Again, we will learn functions from data. That’s what we’re here to do. 1.2 Machine Learning Tasks When doing machine learning, we will classify our tasks into one of two categories, supervised or unsupervised learning.27 Within these two broad categories of ML tasks, we will define some specifics. 1.2.1 Supervised Learning In supervised learning, we want to “predict” a specific response variable. (The response variable might also be called the target or outcome variable.) In the following examples, this is the y variable. Supervised learning tasks are called regression if the response variable is numeric. If a supervised learning tasks has a categorical response, it is called classification. 1.2.1.1 Regression In the regression task, we want to predict numeric response variables. The non-response variables, which we will call the feature variables, or simply features can be either categorical or numeric.28 x1 x2 x3 y A -0.66 0.48 14.09 A 1.55 0.97 2.92 A -1.19 -0.81 15.00 A 0.15 0.28 9.29 B -1.09 -0.16 17.57 B 1.61 1.94 2.12 B 0.04 1.72 8.92 A 1.31 0.36 4.40 C 0.98 0.30 4.40 C 0.88 -0.39 4.52 With the data above, our goal would be to learn a function that takes as input values of the three features (x1, x2, and x3) and returns a prediction (best guess) for the true (but usually unknown) value of the response y. For example, we could obtain some “new” data that does not contain the response. x1 x2 x3 B -0.85 -2.41 We would then pass this data to our function, which would return a prediction of the value of y. Stated mathematically, our prediction will often be an estimate of the conditional mean of \\(Y\\), given values of the \\(\\boldsymbol{X}\\) variables. \\[ \\mu(\\boldsymbol{x}) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] In other words, we want to learn this function, \\(\\mu(\\boldsymbol{x})\\). Much more on this later.29 1.2.1.2 Classification Classification is similar to regression, except it considers categorical response variables. x1 x2 x3 y Q 0.46 5.42 B Q 0.72 0.83 C Q 0.93 5.93 B Q 0.26 5.68 A P 0.46 0.49 B P 0.94 3.09 B P 0.98 2.34 C P 0.12 5.43 C Q 0.47 2.68 B P 0.56 5.02 B As before we want to learn a function from this data using the same inputs, except this time, we want it to output one of A, B, or C for predictions of the y variable. Again, consider some new data: x1 x2 x3 P 0.96 5.33 While ultimately we would like our function to return one of A, B, or C, what we actually would like is an intermediate return of probabilities that y is A, B, or C. In other words, we are attempting to estimate the conditional probability that \\(Y\\) is each of the possible categories, given values of the \\(\\boldsymbol{X}\\) values. \\[ p_k(\\boldsymbol{x}) = P\\left[ Y = k \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] We want to learn this function, \\(p_k(\\boldsymbol{x})\\). Much more on this later. 1.2.2 Unsupervised Learning Unsupervised learning is a very broad task that is rather difficult to define. Essentially, it is learning without a response variable. To get a better idea about what unsupervised learning is, consider some specific tasks. x1 x2 x3 x4 x5 2.74 0.46 5.42 4.43 2.28 2.81 0.72 0.83 4.87 2.61 0.86 0.93 5.93 2.33 0.22 2.49 0.26 5.68 4.11 5.84 1.93 0.46 0.49 0.02 2.59 -8.44 -9.06 -6.91 -5.00 -4.25 -7.79 -9.02 -7.66 -9.96 -4.67 -9.60 -9.88 -4.57 -8.75 -6.16 -8.03 -9.53 -7.32 -4.56 -4.17 -7.88 -9.44 -4.98 -6.33 -6.29 1.2.2.1 Clustering Clustering is essentially the task of grouping the observations of a dataset. In the above data, can you see an obvious grouping? (Hint: Compare the first five observations to the second five observations.) In general, we try to group observations that are similar. 1.2.2.2 Density Estimation Density estimation tries to do exactly what the name implies, estimate the density. In this case, the joint density of \\(X_1, X_2, X_3, X_4, X_5\\). In other words, we would like to learn the function that generated this data.30 1.2.2.3 Outlier Detection Consider some new data: x1 x2 x3 x4 x5 67 66.68 66.26 69.49 70 Was this data generated by the same process as the data above? If we don’t believe so, we would call it an outlier. 1.3 Open Questions The two previous sections were probably more confusing than helpful. But of course, because we haven’t started learning yet! Hopefully, you are currently pondering one very specific question: How do we learn functions from data? That’s what this text will be about! We will spend a lot of time on this question. It is what us statisticians call fitting a model. On some level the answer is: look at a bunch of old data before predicting on new data. While we will dedicate a large amount of time to answering this question, sometimes, some of the details might go unanswered. Since this is an introductory text, we can only go so far. However, as long as we answer another question, this will be OK. How do we evaluate how well learned functions work? This text places a high priority on being able to do machine learning, specifically do machine learning in R. You can actually do a lot of machine learning without fully understanding how the learning is taking place. That makes the evaluation of ML models extremely important. This is a purposefully narrow view of machine learning. Obviously there’s a lot more to ML, but the author believes this statement will help readers understand that the methods learned in this text are simply tools that must be evaluated as a part of a larger analysis.↩ An alternative title of this book could be: ML is boring but useful.↩ There are certainly people who do legitamtely work on AI, but the strong statement is made here to try to downplay the hype.↩ There are technically other tasks such as reinforcement learning and semi-supervised learning, but they are outside the scope of this text. To understand these advanced tasks, you should first learn the basics!↩ These variables are often called “predictor” variables, but we find this nomenclature to be needlessly confusing.↩ For now, just understand that we are able to make a “best guess” for a new observation.↩ You could take the position that this is the only machine learning task, and all other tasks are subset of this task. We’ll hold off on explaining this for a while.↩ "],["linear-regression.html", "Chapter 2 Linear Regression 2.1 Explanation versus Prediction 2.2 Setup 2.3 Mathematical Setup 2.4 Linear Regression Models 2.5 Using lm() 2.6 The predict() Function 2.7 Data Splitting 2.8 Regression Metrics 2.9 Example: “Simple” Simulated Data 2.10 Example: Diamonds Data 2.11 Example: Credit Card Data", " Chapter 2 Linear Regression This chapter will discuss linear regression models, but for a very specific purpose: using linear regression models to make predictions. Specifically, we will discuss: The regression function and estimating conditional means. Using the lm() and predict() functions in R. Data splits to evaluate model performance for machine learning tasks. Source: linear-regression.Rmd 2.1 Explanation versus Prediction Before we even begin to discuss regression, we make a bold announcement: STAT 432 is not a course about inference. It is very possible that there will be zero causal claims in this book. While it would certainly be nice (but extremely difficult) to uncover causal relationships, our focus will be on predictive relationships. Suppose (although it is likely untrue) that there is a strong correlation between wearing a wrist watch, and car accidents. Depending on your frame of reference, you should view this information in very different ways. Suppose you are a car insurance company. This is great news! You can now more accurately predict the number of accidents of your policy holders if you know whether or not they wear a wrist watch. For the sake of understanding how much your company will need to pay out in a year, you don’t care what causes accidents, you just want to be able to predict (estimate) the number of accidents. Suppose you are a car driver. As a driver, you want to stay safe. That is, you want to do things that decrease accidents. In this framing, you care about things that cause accidents, not things that predict accidents. In other words, this correlation information should not lead to you throwing away your wrist watch. Disclaimer: Extremely high correlation should not simply be ignored. For example, there is a very high correlation between smoking and lung cancer.31 However, this strong correlation is not proof that smoking causes lung cancer. Instead, additional study is needed to rule out confounders, establish mechanistic relationships, and more. 2.2 Setup We now introduce the regression task. Regression is a subset of a broader machine learning tasks called supervised learning, which also include classification. (We will return later to discuss supervised learning in general after getting through some specifics of regression and classification.) Stated simply, the regression tasks seeks to estimate (predict) a numeric quantity. For example: Estimating the salary of a baseball player. Estimating the price of a home for sale. Estimating the credit score of a bank customer, Estimating the number of downloads of a podcast. Each of these quantities is some numeric value. The goal of regression is to estimate (predict) these quantities when they are unknown through the use of additional, possibly correlated quantities, for example the offensive and defensive statistics of a baseball player, or the location and attributes of a home. 2.3 Mathematical Setup To get a better grasp of what regression is, we move to defining the task mathematically. Consider a random variable \\(Y\\) which represents a response (or outcome or target) variable, and \\(p\\) feature variables \\(\\boldsymbol{X} = (X_1, X_2, \\ldots, X_p)\\). Features are also called covariates or predictors. (We find the “predictors” nomenclature to be problematic when discussing prediction tasks.) In the most common regression setup, we assume that the response variable \\(Y\\) is some function of the features, plus some random noise. \\[ Y = f(\\boldsymbol{X}) + \\epsilon \\] We call \\(f(\\boldsymbol{X})\\) the signal. This \\(f\\) is the function that we would like to learn. We call \\(\\epsilon\\) the noise. We do not want to learn this which we risk if we overfit. (More on this later.) So our goal will be to find some \\(f\\) such that \\(f(\\boldsymbol{X})\\) is close to \\(Y\\). But how do we define close? There are many ways but we will start with, and most often consider, squared error loss. Specifically, we define a loss function, \\[ L(Y, f(\\boldsymbol{X})) \\triangleq \\left(Y - f(\\boldsymbol{X})\\right) ^ 2 \\] Now we can clarify the goal of regression, which is to minimize the above loss, on average. We call this the risk of estimating \\(Y\\) using \\(f(\\boldsymbol{X})\\). \\[ R(Y, f(\\boldsymbol{X})) \\triangleq \\mathbb{E}[L(Y, f(\\boldsymbol{X}))] = \\mathbb{E}_{\\boldsymbol{X}, Y}[(Y - f(\\boldsymbol{X})) ^ 2] \\] Before attempting to minimize the risk, we first re-write the risk after conditioning on \\(\\boldsymbol{X}\\). \\[ \\mathbb{E}_{\\boldsymbol{X}, Y} \\left[ (Y - f(\\boldsymbol{X})) ^ 2 \\right] = \\mathbb{E}_{\\boldsymbol{X}} \\mathbb{E}_{Y \\mid \\boldsymbol{X}} \\left[ ( Y - f(\\boldsymbol{X}) ) ^ 2 \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] Minimizing the right-hand side is much easier, as it simply amounts to minimizing the inner expectation with respect to \\(Y \\mid \\boldsymbol{X}\\), essentially minimizing the risk pointwise, for each \\(\\boldsymbol{x}\\). It turns out, that the risk is minimized by the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\), \\[ \\mu(\\boldsymbol{x}) \\triangleq \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] which we call the regression function. (This is not a learned function, this is the function we would like to learn in order to minimize the squared error loss on average. \\(f\\) is any function, \\(\\mu\\) is the function that would minimize squared error loss on average if we knew if, but will instead need to learn it form the data. Note that \\(\\boldsymbol{x}\\) represents (potential) realized values of the random variables \\(\\boldsymbol{X}\\). \\[ \\boldsymbol{x} = (x_1, x_2, \\ldots, x_p) \\] We can now state the goal of the regression task: we want to estimate the regression function. How do we do that? 2.4 Linear Regression Models What do linear regression models do? They estimate the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\)! (How convenient.) Consider the following probability model \\[ Y = 1 - 2x - 3x ^ 2 + 5x ^ 3 + \\epsilon \\] where \\(\\epsilon \\sim \\text{N}(0, \\sigma^2)\\). Alternatively we could write \\[ Y \\mid X \\sim \\text{N}(1 - 2x - 3x ^ 2 + 5x ^ 3, \\sigma^2) \\] This perhaps makes it clearer that \\[ \\mu(x) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] = 1 - 2x - 3x ^ 2 + 5x ^ 3 \\] What do linear models do? More specifically than before, linear regression models estimate the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\) by assuming this conditional mean is a linear combination of the feature variables. Suppose for a moment that we did not know the above true probability model, or even the more specifically the regression function. Instead, all we had was some data, \\((x_i, y_i)\\) for \\(i = 1, 2, \\ldots, n\\). x y -0.47 -0.06 -0.26 1.72 0.15 1.39 0.82 0.68 -0.60 -0.27 0.80 1.55 0.89 0.76 0.32 -0.40 0.26 -1.85 -0.88 -1.85 How do we fit (or “train” in ML language) a linear model with this data? In order words, how to be learn the regression function from this data with a linear regression model? First, we need to make assumptions about the form of the regression function, up to, but not including some unknown parameters. Consider three possible linear models, in particular, three possible regression functions. Degree 1 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x \\] Degree 3 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 \\] Degree 9 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] These are chosen mostly arbitrarily for illustrative purposes which we’ll see in a moment. So how do we actually fit these models, that is train them, with the given data. We have a couple of options: Maximum Likelihood or Least Squares! In this case, they actually produce the same result, so we use least squares for simplicity of explanation. To fit the degree 3 polynomial using least squares, we minimize \\[ \\sum_{i = 1}^{n}\\left(y_i - (\\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\beta_3 x_i^3)\\right) ^ 2 \\] Skipping the details of the minimization, we would acquire \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), \\(\\hat{\\beta}_2\\), and \\(\\hat{\\beta}_3\\) which are estimates of \\({\\beta}_0\\), \\({\\beta}_1\\), \\({\\beta}_2\\), and \\({\\beta}_3\\). Taken together, we would have \\[ \\hat{\\mu}(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2^2 + \\hat{\\beta}_3 x_3^3 \\] which is then an estimate of \\(\\mu(x)\\). While in this case, it will almost certainly not be the case that \\(\\hat{\\beta}_0 = 1\\) or \\(\\hat{\\beta}_1 = -2\\) or \\(\\hat{\\beta}_2 = -3\\) or \\(\\hat{\\beta}_3 = 5\\), which are the true values of the \\(\\beta\\) coefficients, they are at least reasonable estimates. As a bit of an aside, note that in this case, it is sort of ambiguous as to whether there is one feature, \\(x\\), which is seen in the data, or three features \\(x\\), \\(x^2\\), and \\(x^3\\), which are seen in the model. The truth is sort of in the middle. The data has a single feature, but through feature engineering, we have created two additional features for fitting the model. Note that when using R, you do not need to modify the data to do this, instead you should use R’s formula syntax to specify this feature engineering when fitting the model. More on this when we discuss the lm() function in R. (We introduce this somewhat confusing notion early so we can emphasize that linear models are about linear combinations of features, not necessarily linear relationships. Although, linear models are very good at learning linear relationships.) Suppose instead we had assumed that \\[ \\mu(x) = \\beta_0 + \\beta_1 x \\] This model is obviously flawed as it doesn’t contain enough terms to capture the true regression function. (Later we will say this model is not “flexible” enough.) Or, suppose we had assumed \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] This model is also flawed, but for a different reason. (Later we will say this model is too “flexible.”) After using least squares, we will obtain some \\(\\hat{\\beta}_9\\) even though there is not a 9th degree term in the true regression function! Let’s take a look at this visually. Here we see the three models fit to the data above. The dashed black curve is the true mean function, that is the true mean of \\(Y\\) given \\(x\\), and the solid colored curves are the estimated mean functions. Now we ask the question: which of these models is best? Given these pictures, there are two criteria that we could consider. How close is the estimated regression (mean) function to the data? (Degree 9 is best! There is no error!) How close is the estimated regression (mean) function to the true regression (mean) function? (Degree 3 is best.) From the presentation here, it’s probably clear that the latter is actually what matters. We can demonstrate this by generating some “new” data. These plots match the plots above, except newly simulated data is shown. (The regression functions were still estimated with the previous data.) Note that the degree 3 polynomial matches the data about the same as before. The degree 9 polynomial now correctly predicts none of the new data and makes some huge errors. We will define these concepts more generally later, but for now we note that: The Degree 9 Polynomial is overfitting. It performs well on the data used to fit the model, but poorly on new data. The Degree 1 Polynomial is underfitting. It performs poorly on the data used to fit the model and poorly on new data. There’s a bit of a problem though! In practice, we don’t know the true mean function, and we don’t have the magical ability to simulate new data! Yikes! After we discuss a bit about how to fit these models in R, we’ll return to this issue. (Spoiler: Don’t fit the model to all the available data. Pretend the data you didn’t use is “new” when you evaluate models.) 2.5 Using lm() Before we continue, let’s consider a different data generating process. We first define this data generating process as an R function. gen_mlr_data = function(sample_size = 250) { x1 = round(runif(n = sample_size), 2) x2 = round(runif(n = sample_size), 2) x3 = round(runif(n = sample_size), 2) x4 = factor(sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), size = sample_size, replace = TRUE)) x5 = round(runif(n = sample_size), 2) x6 = round(runif(n = sample_size), 2) y = 2 + x1 + sin(x2) + 3 * x3 ^ 2 + 3 * (x4 == &quot;B&quot;) - 2 * (x4 == &quot;C&quot;) + rnorm(n = sample_size, mean = 0, sd = 0.5) tibble(y, x1, x2, x3, x4, x5, x6) } We then run the function and store the data that is returned. set.seed(42) sim_mlr_data = gen_mlr_data() We then inspect the data. head(sim_mlr_data) ## # A tibble: 6 x 7 ## y x1 x2 x3 x4 x5 x6 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.85 0.91 0.33 0.14 A 0.53 0.24 ## 2 6.22 0.94 0.19 0.18 B 0.7 0.51 ## 3 6.71 0.290 0.27 0.52 B 0.05 0.51 ## 4 7.84 0.83 0.53 0.81 B 0.92 0.76 ## 5 2.75 0.64 0.02 0.12 A 0.03 0.27 ## 6 4.60 0.52 0.8 0.89 A 0.78 0.69 Note that we see only numeric (dbl or int) and factor (fctr) variables. For now, we will require that data contains only these types, and in particular, we will coerce any categorical variables to be factors. (More on this later.) Mathematically, this data was generated from the probability model \\[ Y \\mid \\boldsymbol{X} \\sim \\text{N}(2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C}, \\sigma^2 = 0.25) \\] where \\(x_{4B}\\) is a dummy variable which takes the value 1 when \\(x_4 = \\text{B}\\) and 0 otherwise \\(x_{4C}\\) is a dummy variable which takes the value 1 when \\(x_4 = \\text{C}\\) and 0 otherwise In particular, the true mean function is \\[ \\mu(\\boldsymbol{x}) = 2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C} \\] Now, finally, let’s fit some models it R to this data! To do so, we will use one of the most important functions in R, the lm() function. Let’s specify the form of some assumed mean functions of models that we would like to fit. Model 1 or mod_1 in R \\[ \\mu_1(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 \\] Model 2 or mod_2 in R \\[ \\mu_2(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\] Model 3 or mod_3 in R \\[ \\mu_3(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_{4B} x_{4B} +\\beta_{4C} x_{4C} + \\beta_5 x_5 + \\beta_6 x_6 \\] Model 4 or mod_4 in R \\[ \\mu_4(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\sin(x_2) + \\beta_3 x_3^3 + \\beta_{4B} x_{4B} + \\beta_{4C} x_{4C} \\] Now, finally, R! mod_1 = lm(y ~ x1, data = sim_mlr_data) coef(mod_1) ## (Intercept) x1 ## 3.7834423 0.9530758 Nothing too interesting here about fitting Model 1. We see that the coef() function returns estimate of the \\(\\beta_0\\) and \\(\\beta_1\\) parameters defined above. mod_2 = lm(y ~ x1 + x2, data = sim_mlr_data) coef(mod_2) ## (Intercept) x1 x2 ## 3.8747999 0.9400654 -0.1802538 Again, Model 2 isn’t too interesting. We see that the coef() function returns estimate of the \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\) parameters defined above. mod_3 = lm(y ~ ., data = sim_mlr_data) coef(mod_3) ## (Intercept) x1 x2 x3 x4B x4C ## 1.71015079 0.76017877 0.77637360 3.00479841 3.06812204 -1.93068734 ## x5 x6 ## -0.12248770 -0.04797294 Now, Model 3, we see a couple interesting things. First, the formula syntax y ~ . fits a model with y as the response, and all other variables in the sim_mlr_data data frame (tibble) as features. Also note: we did not manually create the needed dummy variables! R did this for us! levels(sim_mlr_data$x4) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; Because x4 is a factor variable, R uses the first level, A, as the reference level, and then creates dummy variables for the remaining levels. Cool! mod_4 = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = sim_mlr_data) coef(mod_4) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 2.3435702 0.8176247 0.9159963 3.0446314 3.0369950 -1.9421931 Our last model, mod_4 is the most interesting. It makes use of the inhibit function, I(). This allows for on-the-fly feature engineering based on available features. We’re creating new features via R’s formula syntax as we fit the model. To see why this is necessary, consider the following: lm(y ~ (x1 + x2) ^ 2, data = sim_mlr_data) ## ## Call: ## lm(formula = y ~ (x1 + x2)^2, data = sim_mlr_data) ## ## Coefficients: ## (Intercept) x1 x2 x1:x2 ## 4.1800 0.3353 -0.8259 1.3130 This created an interaction term! That means the ^ operator has different uses depending on the context. In specifying a formula, it has a particular use, in this case specifying an interaction term, and all lower order terms. However, inside of I() it will be used for exponentiation. For details, use ?I and ?formula. These are complex R topics, but it will help to start to learn them. For some additional reading on R’s formula syntax, the following two blog posts by Max Kuhn are good reads: The R Formula Method: The Good Parts The R Formula Method: The Bad Parts For the first half of this book, we will always keep the data mostly untouched, and rely heavily on the use of R’s formula syntax. If you are ever interested in what’s happening under the hood when you use the formula syntax, and you recall the linear algebra necessary to perform linear regression, the model.matrix() function will be useful. head(model.matrix(mod_4)) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 1 1 0.91 0.32404303 0.002744 0 0 ## 2 1 0.94 0.18885889 0.005832 1 0 ## 3 1 0.29 0.26673144 0.140608 1 0 ## 4 1 0.83 0.50553334 0.531441 1 0 ## 5 1 0.64 0.01999867 0.001728 0 0 ## 6 1 0.52 0.71735609 0.704969 0 0 Back to talking about mod_4. Recall that we had assumed that \\[ \\mu_4(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\sin(x_2) + \\beta_3 x_3^3 + \\beta_{4B} x_{4B} + \\beta_{4C} x_{4C} \\] Also recall that the true mean function is \\[ \\mu(\\boldsymbol{x}) = 2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C} \\] Because we know this, we can investigate how well our model is performing. We know the true values of the parameters, in this case \\(\\beta_0 = 2\\) \\(\\beta_1 = 1\\) \\(\\beta_2 = 1\\) \\(\\beta_3 = 3\\) \\(\\beta_{4B} = 3\\) \\(\\beta_{4C} = -2\\) \\(\\beta_5 = 0\\) (\\(x_5\\) is not used in the true mean function.) \\(\\beta_6 = 0\\) (\\(x_6\\) is not used in the true mean function.) We also have the estimated coefficients from mod_4. coef(mod_4) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 2.3435702 0.8176247 0.9159963 3.0446314 3.0369950 -1.9421931 \\(\\hat{\\beta}_0 = 2.34\\) \\(\\hat{\\beta}_1 = 0.82\\) \\(\\hat{\\beta}_2 = 0.92\\) \\(\\hat{\\beta}_3 = 3.04\\) \\(\\hat{\\beta}_{4B} = 3.04\\) \\(\\hat{\\beta}_{4C} = -1.94\\) \\(\\hat{\\beta}_5 = 0\\) (We assumed \\(x_5\\) is not used in the true mean function.) \\(\\hat{\\beta}_6 = 0\\) (We assumed \\(x_6\\) is not used in the true mean function.) Our estimated regression (mean) function is then \\[ \\hat{\\mu}_4(\\boldsymbol{x}) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 \\sin(x_2) + \\hat{\\beta}_3 x_3^3 + \\hat{\\beta}_{4B} x_{4B} + \\hat{\\beta}_{4C} x_{4C} \\] Perfect? No. Pretty good? Maybe. However, in reality, this is not a check that we can perform! We still need an evaluation strategy that doesn’t depend on knowing the true model! Note that the other models are “bad” in this case because they are either missing features (mod_1 and mod_2) or the are both missing features and contain unnecessary features (mod_3). 2.6 The predict() Function We stated previously that fitting a linear regression model means that we are learning the regression (mean) function. Now that we fit and stored some models, how do we access these estimated regression (mean) functions? The predict() function! The predict() function will be the workhorse of STAT 432. Let’s see how to use it with models fit using the lm() function. set.seed(3) new_obs = gen_mlr_data(sample_size = 1) new_obs ## # A tibble: 1 x 7 ## y x1 x2 x3 x4 x5 x6 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.751 0.17 0.81 0.38 C 0.6 0.6 Suppose we wanted to estimate the mean of \\(Y\\) when \\(x_1 = 0.17\\) \\(x_2 = 0.81\\) \\(x_3 = 0.38\\) \\(x_4 = \\text{C}\\) \\(x_5 = 0.38\\) \\(x_6 = 0.38\\) In other words, we want to estimate \\[ \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = \\mathbb{E}[Y \\mid X_1 = 0.17, X_2 = 0.81, X_3 = 0.38, X_4 = \\text{C}, X_5 = 0.6, X_6 = 0.6] \\] The predict() function to the rescue! predict(mod_1, new_obs) ## 1 ## 3.945465 What’s being returned here? \\[ \\hat{\\mu}_1(\\texttt{new_obs}) = \\hat{\\mathbb{E}}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = 3.9454652 \\] The predict function, together with a trained model, is the estimated regression (mean) function! Supply a different trained model, then you get that estimated regression (mean) function. predict(mod_4, new_obs) ## 1 ## 1.370883 What’s being returned here? \\[ \\hat{\\mu}_4(\\texttt{new_obs}) = \\hat{\\mathbb{E}}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = 1.3708827 \\] We could compare these two estimates of the conditional mean of \\(Y\\) to the true value of y observed in the observation. More on that in the next section. If given an entire dataset, instead of a single observation, predict() returns the estimated conditional mean of each observation. set.seed(9) some_more_data = gen_mlr_data(sample_size = 10) predict(mod_4, some_more_data) ## 1 2 3 4 5 6 7 8 ## 7.8896349 5.4061018 1.3788387 0.8560024 6.6246872 8.2203544 3.2140060 3.5738889 ## 9 10 ## 5.9928135 8.4908895 Neat! A warning: Do not name the second argument to the predict function. This will cause issues because sometimes the name of that argument is newdata, as it is here, but sometimes it is data. If you use the wrong name, bad things will happen. It is safer to simply never name this argument. (However, in general, arguments after the first should be named. The predict() function is the exception.) 2.7 Data Splitting (Note: Many readers will have possibly seen some machine learning previously. For now, please pretend that you have never heard of or seen cross-validation. Cross-validation will clutter the initial introduction of many concepts. We will return to and formalize it later.) OK. So now we can fit models, and make predictions (create estimates of the conditional mean of \\(Y\\) given values of the features), how do we evaluate how well our models perform, without knowing the true model! First, let’s state a somewhat specific goal. We would like to train models that generalize well, that is, perform well on “new” or “unseen” data that was not used to train the model. To accomplish this goal, we’ll just “create” a dataset that isn’t used to train the model! To create it, we will just split it off. (We’ll actually do so twice.) First, denote the entire available data as \\(\\mathcal{D}\\). \\[ \\mathcal{D} = \\{ (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}, \\ i = 1, 2, \\ldots n \\} \\] We first split this data into a train and test set. We will discuss these two dataset ad nauseam, but let’s set two rules right now. You can do whatever you would like with the training data. However, it is best used to train, evaluate, and select models. Do not, ever, for any reason, fit a model using test data! Additionally, you should not select models using test data. In STAT 432, we will only use test data to provide a final estimate of the generalization error of a chosen model. (Much more on this along the way.) Again, do not, ever, for any reason, fit a model using test data! I repeat: Do not, ever, for any reason, fit a model using test data! (You’ve been warned.) To perform this split, we will randomly select some observations for the train (trn) set, the remainder will be used for the test (tst) set. \\[ \\mathcal{D} = \\mathcal{D}_{\\texttt{trn}} \\cup \\mathcal{D}_{\\texttt{tst}} \\] As a general guiding heuristic, use 80% of the data for training, 20% for testing. In addition to the train-test split, we will further split the train data into estimation and validation sets. These are somewhat confusing terms, developed for STAT 432, but hear us out. To perform this split, we will randomly select some observations (from the train set) for the estimation (est) set, the remainder will be used for the validation (val) set. \\[ \\mathcal{D}_{\\texttt{trn}} = \\mathcal{D}_{\\texttt{est}} \\cup \\mathcal{D}_{\\texttt{val}} \\] Again, use 80% of the data for estimation, 20% for validation. The need for this second split might not become super clear until later on, but the general idea is this: Fit a bunch of candidate models to the estimation data. (Think of this as the data to estimate the model parameters. That’s how we chose the name.) Using these candidate models, evaluate how well they perform using the validation data. After evaluating and picking a single model, re-fit this model to the entire training dataset. Provide an estimate of how well this model performs using the test data. Now that we have data for estimation, and validation, we need some metrics for evaluating these models. 2.8 Regression Metrics If our goal is to “predict” then we want small errors. In general there are two types of errors we consider: Squared Errors: \\((y_i - \\hat{\\mu}(\\boldsymbol{x}_i)) ^2\\) Absolute Errors: \\(|y_i - \\hat{\\mu}(\\boldsymbol{x}_i)|\\) In both cases, we will want to consider the average errors made. We define two metrics. Root Mean Square Error (RMSE) \\[ \\text{rmse}\\left(\\hat{f}_{\\texttt{set_f}}, \\mathcal{D}_{\\texttt{set_D}} \\right) = \\sqrt{\\frac{1}{n_{\\texttt{set_D}}}\\displaystyle\\sum_{i \\in {\\texttt{set_D}}}^{}\\left(y_i - \\hat{f}_{\\texttt{set_f}}({x}_i)\\right)^2} \\] Mean Absolute Error (MAE) \\[ \\text{mae}\\left(\\hat{f}_{\\texttt{set_f}}, \\mathcal{D}_{\\texttt{set_D}} \\right) = \\frac{1}{n_{\\texttt{set_D}}}\\displaystyle\\sum_{i \\in {\\texttt{set_D}}}^{}\\left|y_i - \\hat{f}_{\\texttt{set_f}}({x}_i)\\right| \\] \\(\\hat{f}_{\\texttt{set_f}}\\) is a function \\(f\\) estimated using a model fit to some dataset \\(\\texttt{set_f}\\). The \\((x_i, y_i)\\) are data from dataset \\(\\mathcal{D}_{\\texttt{set_D}}\\). For both, smaller is better. (Less error on average.) In both, we note both the data that the model was fit to, as well as the data the model is evaluated on. Depending on the data used for these different sets, we “define” different metrics. For example, for RMSE, we have: Train RMSE: Evaluate a model fit to estimation data, using estimation data. \\[ \\text{RMSE}_{\\texttt{trn}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{est}}, \\mathcal{D}_{\\texttt{est}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{est}}}\\displaystyle\\sum_{i \\in {\\texttt{est}}}^{}\\left(y_i - \\hat{f}_{\\texttt{est}}({x}_i)\\right)^2} \\] Validation RMSE: Evaluate a model fit to estimation data, using validation data. \\[ \\text{RMSE}_{\\texttt{val}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{est}}, \\mathcal{D}_{\\texttt{val}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{val}}}\\displaystyle\\sum_{i \\in {\\texttt{val}}}^{}\\left(y_i - \\hat{f}_{\\texttt{est}}({x}_i)\\right)^2} \\] Test RMSE: Evaluate a model fit to training data, using test data. \\[ \\text{RMSE}_{\\texttt{tst}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{trn}}, \\mathcal{D}_{\\texttt{tst}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{tst}}}\\displaystyle\\sum_{i \\in {\\texttt{tst}}}^{}\\left(y_i - \\hat{f}_{\\texttt{trn}}({x}_i)\\right)^2} \\] For the rest of this chapter, we will largely ignore train error. It’s a bit confusing, since it doesn’t use the full training data! However, think of training error this way: training error evaluates how well a model performs on the data used to fit the model. (This is the general concept behind “training error.” Others might simply call the “estimation” set the training set. We use “estimation” so that we can reserve “train” for the full training dataset, not just the subset use to initially fit the model.) Let’s return to the sim_mlr_data data and apply these splits and metrics to this data. # test-train split mlr_trn_idx = sample(nrow(sim_mlr_data), size = 0.8 * nrow(sim_mlr_data)) mlr_trn = sim_mlr_data[mlr_trn_idx, ] mlr_tst = sim_mlr_data[-mlr_trn_idx, ] Here we randomly select 80% of the rows of the full data, and store these indices as mlr_trn_idx. We then create the mlr_trn and mlr_tst datasets by either selecting or anti-selecting these rows from the original dataset. # estimation-validation split mlr_est_idx = sample(nrow(mlr_trn), size = 0.8 * nrow(mlr_trn)) mlr_est = mlr_trn[mlr_est_idx, ] mlr_val = mlr_trn[-mlr_est_idx, ] We then repeat the process from above within the train data. Now, let’s compare mod_3 and mod_4. To do so, we first fit both models to the estimation data. mod_3_est = lm(y ~ ., data = mlr_est) mod_4_est = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = mlr_est) We then calculate the validation error for both. Because we will do it so often, we go ahead and write a function to calculate RMSE, given vectors of the actual values (from the data used to evaluate) and the predictions from the model. calc_rmse = function(actual, predicted) { sqrt(mean((actual - predicted) ^ 2)) } # calculate validation RMSE, model 3 calc_rmse(actual = mlr_val$y, predicted = predict(mod_3_est, mlr_val)) ## [1] 0.5788282 # calculate validation RMSE, model 4 calc_rmse(actual = mlr_val$y, predicted = predict(mod_4_est, mlr_val)) ## [1] 0.5452852 Here we see that mod_4_est achieves a lower validation error, so we move forward with this model. We then refit to the full train data, then evaluate on test. mod_4_trn = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = mlr_trn) # calculate test RMSE, model 4 calc_rmse(actual = mlr_tst$y, predicted = predict(mod_4_trn, mlr_tst)) ## [1] 0.538057 We ignore the validation metrics. (We already used them for selecting a model.) This test RMSE is our estimate of how well our selected model will perform on unseen data, on average (in a squared error sense). Note that for selecting a model there is no difference between MSE and RMSE, but for the sake of understanding, RMSE has preferential units, the same units as the response variables. (Whereas MSE has units squared.) We will always report RMSE. 2.8.1 Graphical Evaluation In addition to numeric evaluations, we can evaluate a regression model graphically, in particular with a predicted versus actual plot. plot( x = mlr_tst$y, y = predict(mod_4_trn, mlr_tst), pch = 20, col = &quot;darkgrey&quot;, xlim = c(-1, 10), ylim = c(-1, 10), main = &quot;Predicted vs Actual, Model 4, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() The closer to the line the better. Also, the less of a pattern the better. In other words, this plot will help diagnose if our model is making similar sized errors for all predictions, or if there are systematic differences. It can also help identify large errors. Sometimes, errors can be on average small, but include some huge errors. In some settings, this may be extremely undiserable. This might get you thinking about “checking the assumptions” of a linear model. Assessing things like: normality, constant variance, etc. Note that while these are nice things to have, we aren’t really concerned with these things. If we care how well our model predicts, then we will directly evaluate how well it predicts. Least squares is least squares. It minimizes errors. It doesn’t care about model assumptions. 2.9 Example: “Simple” Simulated Data Let’s return to our initial dataset with a single feature \\(x\\). This time we’ll generate more data, and then split it. cubic_mean = function(x) { 1 - 2 * x - 3 * x ^ 2 + 5 * x ^ 3 } gen_slr_data = function(sample_size = 100, mu) { x = runif(n = sample_size, min = -1, max = 1) y = mu(x) + rnorm(n = sample_size) tibble(x, y) } set.seed(3) sim_slr_data = gen_slr_data(sample_size = 100, mu = cubic_mean) # test-train split slr_trn_idx = sample(nrow(sim_slr_data), size = 0.8 * nrow(sim_slr_data)) slr_trn = sim_slr_data[slr_trn_idx, ] slr_tst = sim_slr_data[-slr_trn_idx, ] # estimation-validation split slr_est_idx = sample(nrow(slr_trn), size = 0.8 * nrow(slr_trn)) slr_est = slr_trn[slr_est_idx, ] slr_val = slr_trn[-slr_est_idx, ] # check data head(slr_trn, n = 10) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.573 -1.18 ## 2 0.807 0.576 ## 3 0.272 -0.973 ## 4 -0.813 -1.78 ## 5 -0.161 0.833 ## 6 0.736 1.07 ## 7 -0.242 2.97 ## 8 0.520 -1.64 ## 9 -0.664 0.269 ## 10 -0.777 -2.02 This time let’s evaluate nine different models. Polynomial models from degree 1 to 9. We fit each model to the estimation data, and store the results in a list. poly_mod_est_list = list( poly_mod_1_est = lm(y ~ poly(x, degree = 1), data = slr_est), poly_mod_2_est = lm(y ~ poly(x, degree = 2), data = slr_est), poly_mod_3_est = lm(y ~ poly(x, degree = 3), data = slr_est), poly_mod_4_est = lm(y ~ poly(x, degree = 4), data = slr_est), poly_mod_5_est = lm(y ~ poly(x, degree = 5), data = slr_est), poly_mod_6_est = lm(y ~ poly(x, degree = 6), data = slr_est), poly_mod_7_est = lm(y ~ poly(x, degree = 7), data = slr_est), poly_mod_8_est = lm(y ~ poly(x, degree = 8), data = slr_est), poly_mod_9_est = lm(y ~ poly(x, degree = 9), data = slr_est) ) So, for example, to access the third model, we would use poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = 3), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = 3)1 poly(x, degree = 3)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = 3)3 ## 6.7638 But let’s back up. That code was terrible to write. Too much repeated code. Consider the following code poly_mod_est_list = map(1:9, ~ lm(y ~ poly(x, degree = .x), data = slr_est)) This accomplishes the same task, but is much cleaner! poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = .x), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = .x)1 poly(x, degree = .x)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = .x)3 ## 6.7638 Here we are using the map() function from the purrr package. The ~ here is used to create a function in place. We’ll consider another way to make it a bit clearer, that is, without writing the function within map(). fit_poly_mod_to_est_data = function(d) { lm(y ~ poly(x, degree = d), data = slr_est) } poly_mod_est_list = map(1:9, fit_poly_mod_to_est_data) Again, the same thing. poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = d), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = d)1 poly(x, degree = d)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = d)3 ## 6.7638 We’ll continue to use this map() function throughout. We’ll explain more and more as we go. Note that the map() function returns a list. The following makes predictions for each of the models, once using the estimation data, once using validation. poly_mod_est_pred = map(poly_mod_est_list, predict, slr_est) poly_mod_val_pred = map(poly_mod_est_list, predict, slr_val) If instead we wanted to return a numeric vector, we would use, map_dbl(). Let’s use this to calculate train and validation RMSE. # calculate train RMSE slr_est_rmse = map_dbl(poly_mod_est_pred, calc_rmse, actual = slr_est$y) # calculate validation RMSE slr_val_rmse = map_dbl(poly_mod_val_pred, calc_rmse, actual = slr_val$y) slr_est_rmse ## [1] 1.5748180 1.2717458 0.9500069 0.9480786 0.9302359 0.9187948 0.9151668 ## [8] 0.9120942 0.9117093 Note that training error goes down as degree goes up. More on this next chapter. slr_val_rmse ## [1] 1.6584930 1.2791685 0.9574010 0.9729928 1.0104449 1.0505615 1.0617693 ## [8] 1.0953461 1.0968283 which.min(slr_val_rmse) ## [1] 3 The model with polynomial degree 3 has the lowest validation error, so we move forward with this model. We re-fit to the full train dataset, then evaluate on the test set one last time. poly_mod_3_trn = lm(y ~ poly(x, degree = 3), data = slr_trn) calc_rmse(actual = slr_tst$y, predicted = predict(poly_mod_3_trn, slr_tst)) ## [1] 0.7198306 Note: There are hints here that this process is a bit unstable. See if you can figure out why. Hint: See what happens when you change the seed to generate or split the data. We’ll return to this issue when we introduce cross-validation, but for now, we’ll pretend we didn’t notice. We’ll round out this chapter with three “real” data examples. 2.10 Example: Diamonds Data For this example, we use (a subset of) the diamonds data from the ggplot2 package. # load (subset of) data set.seed(42) dmnd = ggplot2::diamonds[sample(nrow(diamonds), size = 5000), ] # data prep dmnd = dmnd %&gt;% mutate(cut = factor(cut, ordered = FALSE), color = factor(color, ordered = FALSE), clarity = factor(clarity, ordered = FALSE)) %&gt;% select(-price, everything()) # test-train split dmnd_trn_idx = sample(nrow(dmnd), size = 0.8 * nrow(dmnd)) dmnd_trn = dmnd[dmnd_trn_idx, ] dmnd_tst = dmnd[-dmnd_trn_idx, ] # estimation-validation split dmnd_est_idx = sample(nrow(dmnd_trn), size = 0.8 * nrow(dmnd_trn)) dmnd_est = dmnd_trn[dmnd_est_idx, ] dmnd_val = dmnd_trn[-dmnd_est_idx, ] The code above loads the data, then performs a test-train split, then additionally an estimation-validation split. We then look at the train data. That is we do not even look at the test data. # check data head(dmnd_trn, n = 10) ## # A tibble: 10 x 10 ## carat cut color clarity depth table x y z price ## &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.5 Premium H SI1 59 59 5.22 5.18 3.07 1156 ## 2 1.01 Ideal G SI2 63.2 57 6.33 6.28 3.99 4038 ## 3 0.62 Very Good D SI1 61.3 58 5.47 5.49 3.36 1949 ## 4 0.41 Ideal D VS2 62.4 54 4.78 4.74 2.97 1076 ## 5 0.31 Ideal G IF 61.6 54 4.36 4.4 2.7 853 ## 6 1.08 Ideal I SI1 62.6 53.9 6.51 6.56 4.09 5049 ## 7 0.52 Very Good G VS2 62.4 60 5.14 5.18 3.22 1423 ## 8 1.01 Premium F SI2 60.9 60 6.45 6.42 3.91 3297 ## 9 0.570 Ideal H VS1 61.7 54 5.33 5.36 3.3 1554 ## 10 0.34 Ideal H VS2 62.5 54 4.54 4.49 2.82 689 Our goal here will be to build a model to predict the price of a diamond given it’s characteristics. Let’s create a few EDA plots. Note that these plots do not contain the test data. If they did, we would be using the test data to influence model building and selection, a big no-no. Let’s consider four possible models, each of which we fit to the estimation data. dmnd_mod_1_est = lm(price ~ carat, data = dmnd_est) dmnd_mod_2_est = lm(price ~ carat + x + y + z, data = dmnd_est) dmnd_mod_3_est = lm(price ~ poly(carat, degree = 2) + x + y + z, data = dmnd_est) dmnd_mod_4_est = lm(price ~ poly(carat, degree = 2) + . - carat, data = dmnd_est) Now, let’s calculate the validation RMSE of each. dmnd_mod_list = list( dmnd_mod_1_est, dmnd_mod_2_est, dmnd_mod_3_est, dmnd_mod_4_est ) dmnd_mod_val_pred = map(dmnd_mod_list, predict, dmnd_val) map_dbl(dmnd_mod_val_pred, calc_rmse, actual = dmnd_val$price) ## [1] 1583.558 1517.080 1634.396 1350.659 It looks like model dmnd_mod_4_est achieves the lowest validation error. We re-fit this model, then report the test RMSE. dmnd_mod_4_trn = lm(price ~ poly(carat, degree = 2) + . - carat, data = dmnd_trn) calc_rmse(actual = dmnd_tst$price, predicted = predict(dmnd_mod_4_trn, dmnd_tst)) ## [1] 1094.916 So, on average, this model is “wrong” by about $1000 dollars. However, less-so when it is a low cost diamond, more so with high priced diamonds, as we can see in the plot below. plot( x = dmnd_tst$price, y = predict(dmnd_mod_4_trn, dmnd_tst), pch = 20, col = &quot;darkgrey&quot;, xlim = c(0, 25000), ylim = c(0, 25000), main = &quot;Diamonds: Predicted vs Actual, Model 4, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() Some things to consider: Could you use the predicted versus actual plot to assist in selecting a model with the validation data? Note that the model we have chosen is not necessarily the “best” model. It is simply the model with the lowest validation RMSE. This is currently a very simplistic analysis. Can you improve this model? Would a log transform of price help? 2.11 Example: Credit Card Data Suppose you work for a small local bank, perhaps a credit union, that has a credit card product offering. For years, you relied on credit agencies to provide a rating of your customer’s credit, however, this costs your bank money. One day, you realize that it might be possible to reverse engineer your customers’ (and thus potential customers) credit rating based on the credit ratings that you have already purchased, as well as the demographic and credit card information that you already have, such as age, education level, credit limit, etc. (We make no comment on the legality or ethics of this idea. Consider these before using at your own risk.) So long as you can estimate customers’ credit ratings with a reasonable error, you could stop buying the ratings from an outside agency. Effectively, you will have created your own rating. # load data, coerce to tibble crdt = as_tibble(ISLR::Credit) To perform this analysis, we will use the Credit data form the ISLR package. Note: this is not real data. It has been simulated. # data prep crdt = crdt %&gt;% select(-ID) %&gt;% select(-Rating, everything()) We remove the ID variable as it should have no predictive power. We also move the Rating variable to the last column with a clever dplyr trick. This is in no way necessary, but is useful in creating some plots. # test-train split set.seed(1) crdt_trn_idx = sample(nrow(crdt), size = 0.8 * nrow(crdt)) crdt_trn = crdt[crdt_trn_idx, ] crdt_tst = crdt[-crdt_trn_idx, ] # estimation-validation split crdt_est_idx = sample(nrow(crdt_trn), size = 0.8 * nrow(crdt_trn)) crdt_est = crdt_trn[crdt_est_idx, ] crdt_val = crdt_trn[-crdt_est_idx, ] After train-test and estimation-validation splitting the data, we look at the train data. # check data head(crdt_trn, n = 10) ## # A tibble: 10 x 11 ## Income Limit Cards Age Education Gender Student Married Ethnicity Balance ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 183. 13913 4 98 17 &quot; Mal… No Yes Caucasian 1999 ## 2 35.7 2880 2 35 15 &quot; Mal… No No African … 0 ## 3 123. 8376 2 89 17 &quot; Mal… Yes No African … 1259 ## 4 20.8 2672 1 70 18 &quot;Fema… No No African … 0 ## 5 39.1 5565 4 48 18 &quot;Fema… No Yes Caucasian 772 ## 6 36.5 3806 2 52 13 &quot; Mal… No No African … 188 ## 7 45.1 3762 3 80 8 &quot; Mal… No Yes Caucasian 70 ## 8 43.5 2906 4 69 11 &quot; Mal… No No Caucasian 0 ## 9 23.1 3476 2 50 15 &quot;Fema… No No Caucasian 209 ## 10 53.2 4943 2 46 16 &quot;Fema… No Yes Asian 382 ## # … with 1 more variable: Rating &lt;int&gt; To get a better “look” at the data, consider running the following: skimr::skim(crdt_trn) str(crdt_trn) View(crdt_trn) We also create a pairs plot. We immediately notice three variables that have a strong correlation with Rating: Income, Limit, and Balance. Based on this, we evaluate five candidate models. crdt_mod_list = list( crdt_mod_0_est = lm(Rating ~ 1, data = crdt_est), crdt_mod_1_est = lm(Rating ~ Limit, data = crdt_est), crdt_mod_2_est = lm(Rating ~ Limit + Income + Balance, data = crdt_est), crdt_mod_3_est = lm(Rating ~ ., data = crdt_est), crdt_mod_4_est = step(lm(Rating ~ . ^ 2, data = crdt_est), trace = FALSE) ) crdt_mod_val_pred = map(crdt_mod_list, predict, crdt_val) map_dbl(crdt_mod_val_pred, calc_rmse, actual = crdt_val$Rating) ## crdt_mod_0_est crdt_mod_1_est crdt_mod_2_est crdt_mod_3_est crdt_mod_4_est ## 140.080591 12.244099 12.333767 9.890607 11.575484 From these results, it appears that the additive model, including all terms performs best. We move forward with this model. final_credit_model = lm(Rating ~ ., data = crdt_trn) sqrt(mean((predict(final_credit_model, crdt_tst) - crdt_tst$Rating) ^ 2)) ## [1] 10.47727 It seems that on average, this model errors by about 10 credit points. range(crdt_trn$Rating) ## [1] 93 982 sd(crdt_trn$Rating) ## [1] 157.5897 Given the range of possible ratings, this seem pretty good! What do you think? plot( x = crdt_tst$Rating, y = predict(final_credit_model, crdt_tst), pch = 20, col = &quot;darkgrey&quot;, # xlim = c(0, 25000), ylim = c(0, 25000), main = &quot;Credit: Predicted vs Actual, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() The predicted versus actual plot almost looks too good to be true! Wow! (Oh, wait. This was simulated data…) In summary, if this data were real, we might have an interesting result! Do note, that both this example and the previous should not be considered data analyses, but instead, examples that reinforce how to use the validation and test sets. As part of a true analysis, we will need to be much more careful about some of our decision. More on this later! Up next: nonparametric regression methods. Fun fact: RA Fisher, the most famous statistician, did not believe that smoking caused cancer. It’s actually a part of a larger fasinating story.↩ "],["additional-reading.html", "A Additional Reading A.1 Books A.2 Papers A.3 Blog Posts A.4 Miscellaneous", " A Additional Reading A.1 Books An Introduction to Statistical Learning Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani The Elements of Statistical Learning Trevor Hastie, Robert Tibshirani, and Jerome Friedman Mathematics for Machine Learning Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong Understanding Machine Learning: From Theory to Algorithms Shai Shalev-Shwartz and Shai Ben-David Foundations of Machine Learning Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar The caret Package Max Kuhn Feature Engineering and Selection: A Practical Approach for Predictive Models Max Kuhn and Kjell Johnson Applied Predictive Modeling Max Kuhn and Kjell Johnson Machine Learning: A Probabilistic Perspective Kevin Murphy Probability for Statistics and Machine Learning Anirban DasGupta From Linear Models to Machine Learning Norman Matloff Interpretable Machine Learning Christoph Molnar Grokking Deep Learning Andrew W. Trask A.2 Papers Do we Need Hundreds of Classifiers to Solve Real World Classification Problems? Manuel Fernandez-Delgado, Eva Cernadas, Senen Barro, Dinani Amorim Statistical Modeling: The Two Cultures Leo Breiman 50 Years of Data Science David Donoho A.3 Blog Posts Peekaboo: Don’t cite the No Free Lunch Theorem aleatoric: Overfitting: A Guided Tour Math for Machines: Optimal Boundaries Variance Explained: What’s the difference between data science, machine learning, and artificial intelligence? A.4 Miscellaneous Machine Learning verus Statistics, A Glossary Rob Tibshirani "],["computing.html", "B Computing B.1 Reading B.2 Additional Resources B.3 STAT 432 Idioms", " B Computing STAT 432 is not a course about R. It is however, a course that makes heavy use of R. Because of this, you will need to be familiar with R. This text will point out some things about R along the way, but some previous study of R is necessary. B.1 Reading The following reading suggestions are long. While it may seem daunting to read all of this material, it will likely prove to be valuable. A smart strategy would be: “Read” as much of the information here, where “read” simply means read every single word and line of code, but don’t slow down if you don’t fully understand. Return to some selections from this reading every week spending more time understanding specific sections. Whether you’re a novice or an expert, there is a high probability that any effort towards reading these sources will provide a return. If you use the strategy above, over time you will start to see the bigger picture. Required: Hands-On Programming with R - Garrett Grolemund If you have never used R or RStudio before, Part 1 (Chapters 1 - 3) will be useful. Even if you have used R before, you will likely gain something from reading these sections. Recommended: R for Data Science - Garrett Grolemund, Hadley Wickham This book helps getting you up to speed working with data in R. While it is a lot of reading, Chapters 1 - 21 may prove useful. It probably isn’t worth sitting down and reading this from start to finish right now, but reading it here and there during some free time would be a good idea. Recommended: Advanced R - Hadley Wickham Part I (Chapters 1 - 8) of this book will help create a mental model for working with R. These chapters are not an easy read, so they should be returned to often. Chapter 2 could be safely skipped for our purposes, but is important if you will use R in the long term. Reference: Applied Statistics with R - David Dalpiaz If you are a UIUC student who took the course STAT 420, the first six chapters of that book could serve as a nice refresher, however, the three readings above are preferred. Chapter 6 contain three very useful video playlists and an R Markdown template. Note that the videos were created a few years ago, thus there may be minor differences between then and now, but the general ideas are the same. Video Playlist: R and RStudio Video Playlist: Data in R Video Playlist: R Markdown Template: R Markdown R Markdown will be used throughout the course, but you will not be required to use R Markdown until the final weeks when we begin working on data analyses. At that time, we will suggest some additional reading about R Markdown. When working on quizzes until then, you can use either an R script or an R Markdown document, whichever you are more comfortable with. B.2 Additional Resources In addition to the above readings, the following resources are more specific or more advanced, but could still prove to be useful. B.2.1 R Efficient R programming R Programming for Data Science R Graphics Cookbook Modern Dive What They Forgot to Teach You About R The R Inferno Data Wrangling, Exploration, and Analysis with R The tidyverse Website dplyr Website readr Website tibble Website forcats Website B.2.2 RStudio RStudio IDE Cheatsheet RStudio Resources B.2.3 R Markdown R Markdown Cheatsheet R Markdown: The Definitive Guide - Yihui Xie, J. J. Allaire, Garrett Grolemund R Markdown Cookbook R4DS: R Markdown Chapter B.2.3.1 Markdown Daring Fireball - Markdown: Basics GitHub - Mastering Markdown CommonMark B.3 STAT 432 Idioms R tutorials and advice are plentiful online. While we do not want to discourage you from using the resources above, or using your own creativity, the following sections will specify some strong suggestions for how to use R, RStudio, and R Markdown in STAT 432. In other words, information below here supersedes any information from the above sources. B.3.1 Don’t Restore Old Workspaces Due to some odd default settings in RStudio, some students never clear their R environment. This is a problem for a number of reasons. (It could prevent your results from being reproducible.) To get ready for STAT 432, do the following: Clear your current environment. Change some RStudio defaults. Deselect &quot;Restore .RData into workspace at startup. Set “Save workspace .RData on exit:” to “Never” This will save you a lot of headache in STAT 432 and the future. B.3.2 R Versions You should always use the most up-to-date version of R and RStudio. You must use at least R version 4.0.2. Importantly, R versions after 3.6.0 have slightly different random number generation. Although, even with the most recent version, sometimes R keeps the old random number generation. To check that you are on the most recent random number generation, run: RNGkind() ## [1] &quot;Mersenne-Twister&quot; &quot;Inversion&quot; &quot;Rejection&quot; If your output matches the output above, you’re all set. If not, run: RNGversion(getRversion()) Then re-run RNGkind() and everything should match up and you should be good to go! B.3.3 Packages Be sure to keep your packages up-to-date. To do so: Restart RStudio Click the “Packages” tab Click “Update” Click “Select All” Click “Install Updates” At this point, you may be asked: “Do you want to restart R prior to installing?” Select “Yes.” If asked again, Select “No.” During the update you may be asked “Do you want to install from sources the packages which need compilation? (Yes/no/cancel)” Type no and press enter. (Do the same if you encounter this when installing packages.) Errors often rise when installing packages. Two common tips to overcome these: Simply retry the installation. If you see the name of another package in an error message, try installing that package, then retry installing the original package. B.3.4 Code Style Code needs to be read by two distinct groups: Computers Humans Computers will complain, very loudly, when you write “bad” code, that is code that does not run. We need to write code that is syntactically correct for the computer to be able to “read” our code. Computers only care about syntax. If we relate this to natural language, we would say that computers really only care about grammar and punctuation. They don’t worry about style like phrasing, tone, etc. While computers will complain about bad code, does anyone really care about wasting their time? (OK, sure, computer scientists might.) If we give them bad code, they try to run it, fail, then complain. However, they’re soulless machines, they can handle it. Humans on the other hand have a finite amount of time on this earth. Even if we solve aging, we still have to deal with the heat death of the universe. Thus, while wasting a computer’s time is no big deal, wasting a human’s time is, frankly, immoral. What does this have to do with R programming? Humans are going to read your R code. One of those humans is likely to be you, but future you. To make this reading possible and efficient, you need to develop style. Here is some code that a computer can read, but a human will struggle to read: set.seed(1337);mu=10;sample_size=50;samples=100000;x_bars=rep(0, samples); for(i in 1:samples){x_bars[i]=mean(rpois(sample_size,lambda = mu))} x_bar_hist=hist(x_bars,breaks=50,main=&quot;Histogram of Sample Means&quot;, xlab=&quot;Sample Means&quot;,col=&quot;darkorange&quot;,border = &quot;dodgerblue&quot;) Now, written again, but readable by a human: # set seed for reproducibility set.seed(1337) # setup simulation parameters mu = 10 sample_size = 50 samples = 100000 # create vector to store simulation results x_bars = rep(0, samples) # run simulation for (i in 1:samples) { x_bars[i] = mean(rpois(sample_size, lambda = mu)) } # plot results x_bar_hist = hist( x_bars, breaks = 50, main = &quot;Histogram of Sample Means&quot;, xlab = &quot;Sample Means&quot;, col = &quot;darkorange&quot;, border = &quot;dodgerblue&quot; ) To the computer, these are the same. To a human, one makes you want to pull your hair out, the other you can glance at and have a pretty good idea about what is going on. Style is subjective, but we’ll define some guiding principles, and a few rules. B.3.5 Reference Style So as to not have to define a style from the ground up, we will use the tidyverse style as our initial reference. tidyverse Style Guide We will agree with the vast majority of the guidelines here. The exceptions are listed in the next section. B.3.6 STAT 432 R Style Overrides All commas must be followed by a space. (Additionally, commas should never be preceded by a space.) Infix operators (==, +, -, &lt;-, etc.) should always be surrounded by spaces. Exceptions: :, ::, $, [, [[, ], ]] ^: Use x ^ 2 instead of x^2. You may use = instead of &lt;-. This is very much a minority position in the R community. But we see more examples of it being promoted every day. My reasoning for this is complicated (and I should write more about it soon) but not super important. Instead, what is important: Do not mix assignment operators. Either use = or use &lt;- but do not mix and match in the same script. Never use T or F, only TRUE or FALSE. While this should never happen, take a look at this terrifying example. FALSE == TRUE # checking for equality ## [1] FALSE F == TRUE # checking for equality ## [1] FALSE F = TRUE # A VERY BAD ASSIGNMENT! DO NOT DO THIS! F == TRUE # checking for equality, with a wild result! ## [1] TRUE # TRUE = FALSE # This won&#39;t run, which is good! Do not use ;. This is mostly a readability issue. Do not use attach(). Without going into the details, you will save yourself a lot of headache someday if you follow this advice. Do not use &lt;&lt;-. You probably didn’t know this exists. Pretend that is still the case. Do not set a working directory by using setwd() or any other method. This will make your scripts and R Markdown documents much more reproducible. Do not use absolute paths. Place a space after any # used to create a comment. No more than one newline (blank line) in a row Do not put spaces in filenames. Use dashes - or underscores _. Also consider only using lowercase. Load all packages before setting a seed. Opening (left) curly braces should not be on their own line. Except for the first argument to a function, argument names should be written in function calls. (Exception for the predict() function. Do not name the second argument to the predict() function. If you do, you will regret it eventually!) Place a newline at the end of the file. B.3.7 STAT 432 R Markdown Style Some of the previous section applies here as well, but additionally, some more specific R Markdown style guidelines: No more than one newline (blank line) in a row in an R Markdown document. No more than one newline (blank line) in a row in an R chunk. A newline before and after each chunk in an R Markdown document. No newline to start a chunk. No newline at end of chunk. (The first and last line of each chunk should contain code, or a comment for the first line.) Use headers appropriately! (Short names, good structure.) Load all needed packages at the beginning of an analysis in a single chunk. One plot per chunk! Plotting chunks should return one plot and nothing else. (No numeric printing.) B.3.8 Style Heuristics Now that we’ve overwhelmed you with information about style, we will leave you with the real advice. The most important thing to consider when evaluating the style of your code is consistency. In order, you should be consistent: with yourself! with your group! with your organization! Blindly following the rules is foolish. Breaking rules can be fun! If you do it in a way that makes life easier for everyone, by all mean, do it. B.3.9 Objects and Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. — John Chambers As you continue to sharpen your R skills, keep this quotation in mind. Eventually, you will realize that everything you “do” in R, you do by running a function. To debug your code, you will need to explore the objects returned by functions. To fix your code, you will need to alter the inputs to functions, which are objects. In STAT 432, the objects that we will encounter will almost always be: vectors lists data frames model objects (Mostly lists with a class of the model type.) If you become proficient at creating, manipulating, and accessing these objects, you will likely have success in STAT 432. B.3.10 Print versus Return One of the more confusing aspects of R is the difference between what is returned when running a function, and what is printed when running a function (interactively) as a user. Consider fitting the following linear model. cars_mod = lm(dist ~ speed, data = cars) You might think that you can simply type cars_mod to see what was returned by lm(). cars_mod ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 However, this is not what was returned. This is what was printed. To better understand what was returned, we use the `str() function. str(cars_mod) ## List of 12 ## $ coefficients : Named num [1:2] -17.58 3.93 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot; ## $ residuals : Named num [1:50] 3.85 11.85 -5.95 12.05 2.12 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ effects : Named num [1:50] -303.914 145.552 -8.115 9.885 0.194 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;(Intercept)&quot; &quot;speed&quot; &quot;&quot; &quot;&quot; ... ## $ rank : int 2 ## $ fitted.values: Named num [1:50] -1.85 -1.85 9.95 9.95 13.88 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ assign : int [1:2] 0 1 ## $ qr :List of 5 ## ..$ qr : num [1:50, 1:2] -7.071 0.141 0.141 0.141 0.141 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot; ## .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1 ## ..$ qraux: num [1:2] 1.14 1.27 ## ..$ pivot: int [1:2] 1 2 ## ..$ tol : num 1e-07 ## ..$ rank : int 2 ## ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot; ## $ df.residual : int 48 ## $ xlevels : Named list() ## $ call : language lm(formula = dist ~ speed, data = cars) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language dist ~ speed ## .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot; ## .. .. .. ..$ : chr &quot;speed&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot; ## $ model :&#39;data.frame&#39;: 50 obs. of 2 variables: ## ..$ dist : num [1:50] 2 10 4 22 16 10 18 26 34 17 ... ## ..$ speed: num [1:50] 4 4 7 7 8 9 10 10 10 11 ... ## ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; language dist ~ speed ## .. .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed) ## .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot; ## .. .. .. .. ..$ : chr &quot;speed&quot; ## .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot; ## .. .. ..- attr(*, &quot;order&quot;)= int 1 ## .. .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. .. ..- attr(*, &quot;response&quot;)= int 1 ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed) ## .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot; ## - attr(*, &quot;class&quot;)= chr &quot;lm&quot; This is a huge mess, but most importantly, at the top we are told that cars_mod is a list. (It’s technically a object of class &quot;lm&quot;, but it functions like a list.) class(cars_mod) ## [1] &quot;lm&quot; is.list(cars_mod) ## [1] TRUE Thus to access certain information returned by lm() we need to access cars_mod as a list. cars_mod$coefficients ## (Intercept) speed ## -17.579095 3.932409 Note that what is returned here is a vector, so we could pull out a particular value using vector syntax. cars_mod$coefficients[&quot;speed&quot;] ## speed ## 3.932409 Since lm() truly returns an object of type &quot;lm&quot; we can pass cars_mods to some generic functions, and then specific versions for objects of type &quot;lm&quot; will be used. coef(cars_mod) ## (Intercept) speed ## -17.579095 3.932409 predict(cars_mod, data.frame(speed = 5:10)) ## 1 2 3 4 5 6 ## 2.082949 6.015358 9.947766 13.880175 17.812584 21.744993 summary(cars_mod) ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 Hey, wait, what is returned by summary()? class(summary(cars_mod)) ## [1] &quot;summary.lm&quot; is.list(summary(cars_mod)) ## [1] TRUE The summary() function returns an object of type &quot;summary.lm&quot; which functions as a list! summary(cars_mod)$fstatistic ## value numdf dendf ## 89.56711 1.00000 48.00000 You can also use the View() function, which is specific to RStudio, to view the structure of any object. View(summary(cars_mod)) # RStudio only B.3.11 Help To get documentation about a function in R, simply put a question mark in front of the function name and RStudio will display the documentation, for example: ?log ?sin ?paste ?lm Frequently one of the most difficult things to do when learning R is asking for help. First, you need to decide to ask for help, then you need to know how to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as Stack Exchange. Describe what you expect the code to do. State the end goal you are trying to achieve. (Sometimes what you expect the code to do, is not what you want to actually do.) Provide the full text of any errors you have received. Provide enough code to recreate the error. That is, create a minimal reproducible example. If you follow these steps, you will get your issue resolved much quicker, and possibly learn more in the process. Do not be discouraged by running into errors and difficulties when learning R. (Or any technical skill.) It is simply part of the learning process. While taking STAT 432: Come to office hours! B.3.12 Keyboard Shortcuts This section should be expanded over time, but for now, two strong suggestions: Get in the habit of using the keyboard as much as possible, and the mouse as little as possible. A keyboard is a precise entry tool, a mouse is not. Using a mouse requires you to move your hands, a keyboard does not. Hit the [TAB] key often. Like, all the time. It will autocomplete function and object names. It will autofill argument names. (This removes the need to memorize arguments!) "],["probability.html", "C Probability C.1 Reading C.2 Probability Models C.3 Probability Axioms C.4 Probability Rules C.5 Random Variables C.6 Expectations C.7 Likelihood C.8 References", " C Probability STAT 432 is not a course about probability. STAT 432 is a course that uses probability. We give a very brief review of some necessary probability concepts. As the treatment is less than complete, a list of references is given at the end of the chapter. For example, we ignore the usual recap of basic set theory and omit proofs and examples. Reading the information below will likely be unsatisfying. Instead, we suggest that you skip it, engage with the relevant quizzes, then return as needed for reference. C.1 Reading Required: Probability Distributions in R Reference: STAT 400 @ UIUC: Notes and Homework Reference: MIT 6.041: Video Lectures Reference: MIT 6.041: Lecture Notes Reference: MIT 6.041: Readings Reference: STAT 414 @ PSU: Notes C.2 Probability Models When discussing probability models, we speak of random experiments that produce one of a number of possible outcomes. A probability model that describes the uncertainty of an experiment consists of two elements: The sample space, often denoted as \\(\\Omega\\), which is a set that contains all possible outcomes. A probability function that assigns to an event \\(A\\) a nonnegative number, \\(P[A]\\), that represents how likely it is that event \\(A\\) occurs as a result of the experiment. We call \\(P[A]\\) the probability of event \\(A\\). An event \\(A\\) could be any subset of the sample space, not necessarily a single possible outcome. The probability law must follow a number of rules, which are the result of a set of axioms that we introduce now. C.3 Probability Axioms Given a sample space \\(\\Omega\\) for a particular experiment, the probability function associated with the experiment must satisfy the following axioms. Nonnegativity: \\(P[A] \\geq 0\\) for any event \\(A \\subset \\Omega\\). Normalization: \\(P[\\Omega] = 1\\). That is, the probability of the entire space is 1. Additivity: For mutually exclusive events \\(E_1, E_2, \\ldots\\) \\[ P\\left[\\bigcup_{i = 1}^{\\infty} E_i\\right] = \\sum_{i = 1}^{\\infty} P[E_i] \\] Using these axioms, many additional probability rules can easily be derived. C.4 Probability Rules Given an event \\(A\\), and its complement, \\(A^c\\), that is, the outcomes in \\(\\Omega\\) which are not in \\(A\\), we have the complement rule: \\[ P[A^c] = 1 - P[A] \\] In general, for two events \\(A\\) and \\(B\\), we have the addition rule: \\[ P[A \\cup B] = P[A] + P[B] - P[A \\cap B] \\] If \\(A\\) and \\(B\\) are also disjoint, then we have: \\[ P[A \\cup B] = P[A] + P[B] \\] If we have \\(n\\) mutually exclusive events, \\(E_1, E_2, \\ldots E_n\\), then we have: \\[ P\\left[\\textstyle\\bigcup_{i = 1}^{n} E_i\\right] = \\sum_{i = 1}^{n} P[E_i] \\] Often, we would like to understand the probability of an event \\(A\\), given some information about the outcome of event \\(B\\). In that case, we have the conditional probability rule provided \\(P[B] &gt; 0\\). \\[ P[A \\mid B] = \\frac{P[A \\cap B]}{P[B]} \\] Rearranging the conditional probability rule, we obtain the multiplication rule: \\[ P[A \\cap B] = P[B] \\cdot P[A \\mid B] \\cdot \\] For a number of events \\(E_1, E_2, \\ldots E_n\\), the multiplication rule can be expanded into the chain rule: \\[ P\\left[\\textstyle\\bigcap_{i = 1}^{n} E_i\\right] = P[E_1] \\cdot P[E_2 \\mid E_1] \\cdot P[E_3 \\mid E_1 \\cap E_2] \\cdots P\\left[E_n \\mid \\textstyle\\bigcap_{i = 1}^{n - 1} E_i\\right] \\] Define a partition of a sample space \\(\\Omega\\) to be a set of disjoint events \\(A_1, A_2, \\ldots, A_n\\) whose union is the sample space \\(\\Omega\\). That is \\[ A_i \\cap A_j = \\emptyset \\] for all \\(i \\neq j\\), and \\[ \\bigcup_{i = 1}^{n} A_i = \\Omega. \\] Now, let \\(A_1, A_2, \\ldots, A_n\\) form a partition of the sample space where \\(P[A_i] &gt; 0\\) for all \\(i\\). Then for any event \\(B\\) with \\(P[B] &gt; 0\\) we have Bayes’ Theorem: \\[ P[A_i | B] = \\frac{P[A_i]P[B | A_i]}{P[B]} = \\frac{P[A_i]P[B | A_i]}{\\sum_{i = 1}^{n}P[A_i]P[B | A_i]} \\] The denominator of the latter equality is often called the law of total probability: \\[ P[B] = \\sum_{i = 1}^{n}P[A_i]P[B | A_i] \\] Note: When working with Bayes’ Theorem it is often useful to draw a tree diagram. Two events \\(A\\) and \\(B\\) are said to be independent if they satisfy \\[ P[A \\cap B] = P[A] \\cdot P[B] \\] This becomes the new multiplication rule for independent events. A collection of events \\(E_1, E_2, \\ldots E_n\\) is said to be independent if \\[ P\\left[\\bigcap_{i \\in S} E_i \\right] = \\prod_{i \\in S}P[E_i] \\] for every subset \\(S\\) of \\(\\{1, 2, \\ldots n\\}\\). If this is the case, then the chain rule is greatly simplified to: \\[ P\\left[\\textstyle\\bigcap_{i = 1}^{n} E_i\\right] = \\prod_{i=1}^{n}P[E_i] \\] C.5 Random Variables A random variable is simply a function which maps outcomes in the sample space to real numbers. C.5.1 Distributions We often talk about the distribution of a random variable, which can be thought of as: \\[ \\text{distribution} = \\text{list of possible} \\textbf{ values} + \\text{associated} \\textbf{ probabilities} \\] This is not a strict mathematical definition, but is useful for conveying the idea. If the possible values of a random variables are discrete, it is called a discrete random variable. If the possible values of a random variables are continuous, it is called a continuous random variable. C.5.2 Discrete Random Variables The distribution of a discrete random variable \\(X\\) is most often specified by a list of possible values and a probability mass function, \\(p(x)\\). The mass function directly gives probabilities, that is, \\[ p(x) = p_X(x) = P[X = x]. \\] Note we almost always drop the subscript from the more correct \\(p_X(x)\\) and simply refer to \\(p(x)\\). The relevant random variable is discerned from context The most common example of a discrete random variable is a binomial random variable. The mass function of a binomial random variable \\(X\\), is given by \\[ p(x | n, p) = {n \\choose x} p^x(1 - p)^{n - x}, \\ \\ \\ x = 0, 1, \\ldots, n, \\ n \\in \\mathbb{N}, \\ 0 &lt; p &lt; 1. \\] This line conveys a large amount of information. The function \\(p(x | n, p)\\) is the mass function. It is a function of \\(x\\), the possible values of the random variable \\(X\\). It is conditional on the parameters \\(n\\) and \\(p\\). Different values of these parameters specify different binomial distributions. \\(x = 0, 1, \\ldots, n\\) indicates the sample space, that is, the possible values of the random variable. \\(n \\in \\mathbb{N}\\) and \\(0 &lt; p &lt; 1\\) specify the parameter spaces. These are the possible values of the parameters that give a valid binomial distribution. Often all of this information is simply encoded by writing \\[ X \\sim \\text{bin}(n, p). \\] C.5.3 Continuous Random Variables The distribution of a continuous random variable \\(X\\) is most often specified by a set of possible values and a probability density function, \\(f(x)\\). (A cumulative density or moment generating function would also suffice.) The probability of the event \\(a &lt; X &lt; b\\) is calculated as \\[ P[a &lt; X &lt; b] = \\int_{a}^{b} f(x)dx. \\] Note that densities are not probabilities. The most common example of a continuous random variable is a normal random variable. The density of a normal random variable \\(X\\), is given by \\[ f(x | \\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\cdot \\exp\\left[\\frac{-1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2 \\right], \\ \\ \\ -\\infty &lt; x &lt; \\infty, \\ -\\infty &lt; \\mu &lt; \\infty, \\ \\sigma &gt; 0. \\] The function \\(f(x | \\mu, \\sigma^2)\\) is the density function. It is a function of \\(x\\), the possible values of the random variable \\(X\\). It is conditional on the parameters \\(\\mu\\) and \\(\\sigma^2\\). Different values of these parameters specify different normal distributions. \\(-\\infty &lt; x &lt; \\infty\\) indicates the sample space. In this case, the random variable may take any value on the real line. \\(-\\infty &lt; \\mu &lt; \\infty\\) and \\(\\sigma &gt; 0\\) specify the parameter space. These are the possible values of the parameters that give a valid normal distribution. Often all of this information is simply encoded by writing \\[ X \\sim N(\\mu, \\sigma^2) \\] C.5.4 Distributions in R R is an excellent, if not best, tool for performing probability distribution calculations. For a large number of distributions, it has four built in functions: d*(x, ...) returns the PDF at \\(x\\) (for continuous distributions) or the PMG at \\(x\\) (for discrete distributions) p*(q, ...) returns the CDF at quantile \\(q\\), that is \\(P[X \\leq q]\\) q*(p, ...) returns \\(c\\) such that \\(P[x \\leq c] = p\\) r*(n, ...) returns \\(n\\) randomly generated observations The * can be any of the disributions built in to R. The ... represents additional arguments, including the parameters of the various distributions. C.5.5 Several Random Variables Consider two random variables \\(X\\) and \\(Y\\). We say they are independent if \\[ f(x, y) = f(x) \\cdot f(y) \\] for all \\(x\\) and \\(y\\). Here \\(f(x, y)\\) is the joint density (mass) function of \\(X\\) and \\(Y\\). We call \\(f(x)\\) the marginal density (mass) function of \\(X\\). Then \\(f(y)\\) the marginal density (mass) function of \\(Y\\). The joint density (mass) function \\(f(x, y)\\) together with the possible \\((x, y)\\) values specify the joint distribution of \\(X\\) and \\(Y\\). Similar notions exist for more than two variables. C.6 Expectations For discrete random variables, we define the expectation of the function of a random variable \\(X\\) as follows. \\[ \\mathbb{E}[g(X)] \\triangleq \\sum_{x} g(x)p(x) \\] For continuous random variables we have a similar definition. \\[ \\mathbb{E}[g(X)] \\triangleq \\int g(x)f(x) dx \\] For specific functions \\(g\\), expectations are given names. The mean of a random variable \\(X\\) is given by \\[ \\mu_{X} = \\text{mean}[X] \\triangleq \\mathbb{E}[X]. \\] So for a discrete random variable, we would have \\[ \\text{mean}[X] = \\sum_{x} x \\cdot p(x) \\] For a continuous random variable we would simply replace the sum by an integral. The variance of a random variable \\(X\\) is given by \\[ \\sigma^2_{X} = \\text{var}[X] \\triangleq \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2. \\] The standard deviation of a random variable \\(X\\) is given by \\[ \\sigma_{X} = \\text{sd}[X] \\triangleq \\sqrt{\\sigma^2_{X}} = \\sqrt{\\text{var}[X]}. \\] The covariance of random variables \\(X\\) and \\(Y\\) is given by \\[ \\text{cov}[X, Y] \\triangleq \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] = \\mathbb{E}[XY] - \\mathbb{E}[X] \\cdot \\mathbb{E}[Y]. \\] C.7 Likelihood Consider \\(n\\) iid random variables \\(X_1, X_2, \\ldots X_n\\). We can then write their likelihood as \\[ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\triangleq f(x_1, x_2, \\ldots, x_n; \\theta) = \\prod_{i = 1}^n f(x_i; \\theta) \\] where \\(f(x_1, x_2, \\ldots, x_n; \\theta)\\) is the joint density (or mass) of \\(X_1, X_2, \\ldots X_n\\) and \\(f(x_i; \\theta)\\) is the density (or mass) function of random variable \\(X_i\\) evaluated at \\(x_i\\) with parameter \\(\\theta\\). (Note: The last equality above only holds for iid random variables.) Whereas a probability or density is a function of a possible observed value given a particular parameter value, a likelihood is the opposite. It is a function of a possible parameter values given observed data. Likelihoods are calculated when the data (the \\(x_i\\)) are known and the parameters (\\(\\theta\\)) are unknown. That is, a likelihood and a joint density will “look” the same, that is contain the same symbols. The meaning of these symbols change depending on what is known. If the data is known, and the parameters is unknown, you have a likelihood. If the parameters are known, and the data are unknown, you have a joint density. The definition above is an acknowledgement of this. The likelihood is defined to be the joint density when the data are known but the parameter(s) is unknown. Maximizing a likelihood is a common technique for fitting a model to data, however, most often we maximum the log-likelihood, as the likelihood and log-likelihood obtain their maximum at the same point. \\[ \\log \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) = \\sum_{i = 1}^{n} \\log f(x_i; \\theta) \\] As an example, suppose that the data vector x_data contains observations from a random sample \\(X_1, X_2, \\ldots, X_n\\) that is assumed to be sampled from a Poisson distribution with (unknown) parameter \\(\\lambda\\). set.seed(42) x_data = rpois(n = 25, lambda = 6) # generating data (assume this is not known) head(x_data) # check data ## [1] 9 10 5 8 7 6 We can use R to calculate the likelihood for various possible values of \\(\\lambda\\) given this data. # calculate the likelihood when lambda = 5 prod(dpois(x = x_data, lambda = 5)) ## [1] 2.609375e-30 The above code takes advantage of the vectorized nature of the dpois() function. Often, especially for computational reasons, we prefer to directly obtain the log-likelihood. # calculate the log-likelihood when lambda = 5 sum(log(dpois(x = x_data, lambda = 5))) ## [1] -68.11844 To understand why this is necessary, repeat the above, but with a much larger sample size. Also note that the d*() functions in R have an option to return logged values. # calculate the log-likelihood when lambda = 5 sum(dpois(x = x_data, lambda = 5, log = TRUE)) ## [1] -68.11844 C.8 References Any of the following are either dedicated to, or contain a good coverage of the details of the topics above. Probability Texts Introduction to Probability by Dimitri P. Bertsekas and John N. Tsitsiklis A First Course in Probability by Sheldon Ross Machine Learning Texts with Probability Focus Probability for Statistics and Machine Learning by Anirban DasGupta Machine Learning: A Probabilistic Perspective by Kevin P. Murphy Statistics Texts with Introduction to Probability Probability and Statistical Inference by Robert V. Hogg, Elliot Tanis, and Dale Zimmerman Introduction to Mathematical Statistics by Robert V. Hogg, Joseph McKean, and Allen T. Craig C.8.1 Videos The YouTube channel mathematicalmonk has a great Probability Primer playlist containing lectures on many fundamental probability concepts. Some of the more important concepts are covered in the following videos: Conditional Probability Independence More Independence Bayes Rule "],["statistics.html", "D Statistics D.1 Reading D.2 Statistics D.3 Estimators", " D Statistics STAT 432 is a course about statistics, in particular, some specific statistics. To discuss the statistics of interest in STAT 432, we will need some general concepts about statistics. D.1 Reading Reference: STAT 400 @ UIUC: Notes and Homework Reference: STAT 3202 @ OSU: Fitting a Probability Model Reference: STAT 415 @ PSU: Notes D.2 Statistics In short: a statistic is a function of (sample) data. (This mirrors parameters being functions of (population) distributions. In SAT terminology, statistics : data :: parameter : distribution.) Consider a random variable \\(X\\), with PDF \\(f(x)\\) which defines the distribution of \\(X\\). Now consider the parameter \\(\\mu\\), which we usually refer to as the mean of a distribution. We use \\(\\mu_X\\) to note that \\(\\mu\\) is dependent on the distribution of \\(X\\). \\[ \\mu_X = \\text{E}[X] = \\int_{-\\infty}^{\\infty}xf(x)dx \\] Note that this expression is a function of \\(f(x)\\). When we change the distribution of \\(X\\), that is, it has a different \\(f(x)\\), that effects \\(\\mu\\). Now, given a random sample \\(X_1, X_2, \\ldots, X_n\\), define a statistic, \\[ \\hat{\\mu}(x_1, x_2, \\ldots, x_n) = \\frac{1}{n}\\sum_{i = 1}^{n}x_i \\] Often, we will simplify notation and instead simply write \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{i = 1}^{n}x_i \\] and the fact that \\(\\hat{\\mu}\\) is a function of the sample is implied. (You might also notice that this is the sample mean, which is often denoted by \\(\\bar{x}\\).) Another confusing aspect of statistics is that they are random variables! Sometimes we would write the above as \\[ \\hat{\\mu}(X_1, X_2, \\ldots, X_n) = \\frac{1}{n}\\sum_{i = 1}^{n}X_i \\] When written this way, we are emphasizing that the random sample has not yet be observed, thus is still random. When this is the case, we can investigate the properties of the statistic as a random variable. When the sample has been observed, we use \\(x_1, x_2, \\ldots, x_n\\) to note that we are inputting these observed values into a function, which outputs some value. (Sometimes we, and others, will be notationally sloppy and simply use lower case \\(x\\) and you will be expected to understand via context if we are dealing with random variables or observed values of random variables. This is admittedly confusing.) As a final note, suppose we observe some data \\[ x_1 = 2, x_2 = 1, x_3 =5 \\] and we calculate \\(\\hat{\\mu}\\) given these values. We would obtain \\[ \\hat{\\mu} = \\frac{8}{3} \\approx 2.66 \\] Note that 2.66 is not a statistic. It is the value of a statistic given a particular set of data. The statistic is still \\(\\hat{\\mu}\\) which has output the value 2.66. Statistics output values given some data. D.3 Estimators Estimators are just statistics with a purpose, that is, estimators are statistics that attempt to estimate some quantity of interest, usually some parameter. (In other words, learn from data.) Like statistics, estimators are functions of data that output values, which we call estimates. D.3.1 Properties Bias and Variance Visually Illustrated Because they are just statistics, estimators are simply functions of data. What makes an estimator good? Essentially, an estimator is good if it produces estimates that are close to the thing being estimated. The following properties help to better define this “closeness” as a function of the errors made by estimators. To estimate some parameter \\(\\theta\\) we will consider some estimator \\(\\hat{\\theta}\\). D.3.1.1 Bias The bias of an estimator defines the systematic error of the estimator, that is, how the estimator “misses” on average. \\[ \\text{bias}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[\\hat{\\theta}\\right] - \\theta \\] D.3.1.2 Variance The variance of an estimator defines how close resulting estimates are to each other. (Assuming the estimated was repeated.) \\[ \\text{var}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[ \\left( \\hat{\\theta} - \\mathbb{E}\\left[\\hat{\\theta}\\right] \\right)^2 \\right] \\] D.3.1.3 Mean Squared Error The mean squared error (MSE) is exactly what the name suggests, it is the average squared error of the estimator. Interestingly, the MSE decomposes into terms related to the bias and the variance. We will return to this idea later for a detailed discussion in the context of machine learning. \\[ \\text{MSE}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[\\left(\\hat{\\theta} - \\theta\\right)^2\\right] = \\left(\\text{bias}\\left[\\hat{\\theta}\\right]\\right)^2 + \\text{var}\\left[\\hat{\\theta}\\right] \\] D.3.1.4 Consistency An estimator \\(\\hat{\\theta}_n\\) is said to be a consistent estimator of \\(\\theta\\) if, for any positive \\(\\epsilon\\), \\[ \\lim_{n \\rightarrow \\infty} P\\left( \\left| \\hat{\\theta}_n - \\theta \\right| \\leq \\epsilon\\right) =1 \\] or, equivalently, \\[ \\lim_{n \\rightarrow \\infty} P\\left( \\left| \\hat{\\theta}_n - \\theta \\right| &gt; \\epsilon\\right) =0 \\] We say that \\(\\hat{\\theta}_n\\) converges in probability to \\(\\theta\\) and we write \\(\\hat{\\theta}_n \\overset P \\rightarrow \\theta\\). D.3.2 Example: MSE of an Estimator Consider \\(X_1, X_2, X_3 \\sim N(\\mu, \\sigma^2)\\). Define two estimators for the true mean, \\(\\mu\\). \\[ \\bar{X} = \\frac{1}{n}\\sum_{i = 1}^{3} X_i \\] \\[ \\hat{\\mu} = \\frac{1}{4}X_1 + \\frac{1}{5}X_2 + \\frac{1}{6}X_3 \\] We will now calculate and compare the mean squared error of both \\(\\bar{X}\\) and \\(\\hat{\\mu}\\) as estimators of \\(\\mu\\). First, recall from properties of the sample mean that \\[ \\text{E}\\left[\\bar{X}\\right] = \\mu \\] and \\[ \\text{var}\\left[\\bar{X}\\right] = \\frac{\\sigma^2}{3} \\] Thus we have \\[ \\text{bias}\\left[\\bar{X}\\right] = \\mathbb{E}\\left[\\bar{X}\\right] - \\mu = \\mu - \\mu = 0 \\] Then, \\[ \\text{MSE}\\left[\\bar{X}\\right] \\triangleq \\left(\\text{bias}\\left[\\bar{X}\\right]\\right)^2 + \\text{var}\\left[\\bar{X}\\right] = 0 + \\frac{\\sigma^2}{3} = \\frac{\\sigma^2}{3} \\] Next, \\[ \\text{E}\\left[\\hat{\\mu}\\right] = \\frac{\\mu}{4} + \\frac{\\mu}{5} + \\frac{\\mu}{6} = \\frac{37}{60}\\mu \\] and \\[ \\text{var}\\left[\\hat{\\mu}\\right] = \\frac{\\sigma^2}{16} + \\frac{\\sigma^2}{25} + \\frac{\\sigma^2}{36} = \\frac{469}{3600}\\sigma^2 \\] Now we have \\[ \\text{bias}\\left[\\hat{\\mu}\\right] = \\mathbb{E}\\left[\\hat{\\mu}\\right] - \\mu = \\frac{37}{60}\\mu - \\mu = \\frac{-23}{60}\\mu \\] Then finally we obtain the mean squared error for \\(\\hat{\\mu}\\), \\[ \\text{MSE}\\left[\\hat{\\mu}\\right] \\triangleq \\left(\\text{bias}\\left[\\hat{\\mu}\\right]\\right)^2 + \\text{var}\\left[\\hat{\\mu}\\right] = \\left( \\frac{-23}{60}\\mu \\right)^2 + \\frac{469}{3600}\\sigma^2 \\] Note that \\(\\text{MSE}\\left[\\hat{\\mu}\\right]\\) is small when \\(\\mu\\) is close to 0. D.3.3 Estimation Methods So far we have discussed properties of estimators, but how do we create estimators? You could just define a bunch of estimators and then evaluate them to see what works best (an idea we will return to later in the context of ML) but (the field of) statistics has develop some methods that result in estimators with desirable properties. D.3.4 Maximum Likelihood Estimation Given a random sample \\(X_1, X_2, \\ldots, X_n\\) from a population with parameter \\(\\theta\\) and density or mass \\(f(x; \\theta)\\), we define the likelihood as \\[ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\triangleq f(x_1, x_2, \\ldots, x_n; \\theta) = \\prod_{i = 1}^n f(x_i; \\theta) \\] The Maximum Likelihood Estimator, \\(\\hat{\\theta}\\) \\[ \\hat{\\theta} \\triangleq \\underset{\\theta}{\\text{argmax}} \\ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) = \\underset{\\theta}{\\text{argmax}} \\ \\log \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\] D.3.4.1 Invariance Principle If \\(\\hat{\\theta}\\) is the MLE of \\(\\theta\\) and the function \\(h(\\theta)\\) is continuous, then \\(h(\\hat{\\theta})\\) is the MLE of \\(h(\\theta)\\). D.3.5 Method of Moments While it is very unlikely that we will use the Method of Moments in STAT 432, you should still be aware of its existence. D.3.6 Empirical Distribution Function Consider a random variable \\(X\\) with CDF \\(F(k) = P(X &lt; k)\\) and an iid random sample \\(X_1, X_2, \\ldots, X_n\\). We can estimate \\(F(k)\\) using the Empirical Distribution Function (EDF), \\[ \\hat{F}(k) = \\frac{\\text{# of elements in sample} \\leq k}{n} = \\frac{1}{n} \\sum_{i = 1}^n I(x_i \\leq k) \\] where \\(I(x_i \\leq k)\\) is an indicator such that \\[ I(x_i \\leq k) = \\begin{cases} 1 &amp; \\text{if } x_i \\leq k \\\\ 0 &amp; \\text{if } x_i &gt; k \\end{cases} \\] Given a data vector in R that is assumed to be a random sample, say, y, and some value, say k, it is easy to calculate \\(\\hat{F}(k)\\). set.seed(66) y = rnorm(n = 25, mean = 6, sd = 2.6) # generate sample k = 4 # pick some k head(y) # check data ## [1] 12.042334 6.564140 7.087301 5.503419 5.181420 4.315569 # using the EDF mean(y &lt; k) ## [1] 0.2 # using an estimated normal distribution (not quite using the MLE) pnorm(q = k, mean = mean(y), sd = sd(y)) ## [1] 0.2088465 # using the true (but assumed unknown) CDF pnorm(q = k, mean = 6, sd = 2.6) ## [1] 0.2208782 Note that technically sd(x) does not return the MLE of \\(\\sigma\\) since it uses the unbiased estimator with a denominator of \\(n - 1\\) instead of \\(n\\), but we’re being lazy for the sake of some cleaner code. plot(ecdf(y), col.01line = &quot;white&quot;, verticals = TRUE, do.points = FALSE, xlim = c(0, 15), lwd = 2, lty = 1, ylab = &quot;F(y)&quot;, xlab = &quot;y&quot;, main = &quot;Comparing the EDF to The Truth and MLE&quot;) curve(pnorm(x, mean = 6, sd = 2.6), add = TRUE, xlim = c(0, 15), col = &quot;dodgerblue&quot;, lty = 2, lwd = 2) curve(pnorm(x, mean = mean(y), sd = sd(y)), add = TRUE, xlim = c(0, 15), col = &quot;darkorange&quot;, lty = 3, lwd = 2) legend(&quot;bottomright&quot;, legend = c(&quot;EDF&quot;, &quot;Truth&quot;, &quot;MLE&quot;), col = c(&quot;black&quot;, &quot;dodgerblue&quot;, &quot;darkorange&quot;), lty = 1:3, lwd = 2) grid() We have purposefully used a “small” sample size here so that the EDF is visibly a step function. Modify the code above to increase the sample size. You should notice that the three functions converge as the sample size increases. "],["references.html", "References", " References "]]
